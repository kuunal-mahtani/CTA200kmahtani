{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #importing libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as axes\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"arochime-invpfbB0329+54_32768chan3ntbin\" #setting strings to make calling files easier/shorter, since most of them share the same name\n",
    "fold = \"foldspec_2018-08-16T10:\"\n",
    "icount = \"icount_2018-08-16T10:\"\n",
    "end = \".000+30.000000000000004sec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_min_test(num): #function to determine whether time is in half a minute or whole minute\n",
    "    if num == 30:\n",
    "        return '30'\n",
    "    else:\n",
    "        return '00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = np.loadtxt('pulse_times.txt').T #loading file of times of pulses\n",
    "pt = pt.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filenames,i): #function for loading in files in a for loop\n",
    "    data_fold = np.load(start+fold+str(filenames[0,i])+\":\"+half_min_test(filenames[1,i])+end+\".npy\")    #loading data from folded pulses\n",
    "    data_count = np.load(start+icount+str(filenames[0,i])+\":\"+half_min_test(filenames[1,i])+end+\".npy\") #loading data from icount file\n",
    "    return data_fold, data_count ## shape = (3,32768,512,4), (3,32768,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data_fold,data_count):                               #function for normalizing raw data\n",
    "    norm_data = data_fold/data_count.reshape(data_count.shape+(1,))\n",
    "    return norm_data                                               #shape = (3,32768,512,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meandiv_2(norm_data,i):                                                  #function for dividing normalized data by mean\n",
    "                                                                           #of normalized data for a given time along the\n",
    "                                                                           #frequency axis to 'clean' it up\n",
    "    mean_div = norm_data[i,:,:]/norm_data[i,:,:].mean(1, keepdims=True)\n",
    "    return mean_div                                                        #shape = (32768,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_baseline(mean_div):          #function for removing baseline from a given file\n",
    "    f_summed = np.sum(mean_div,axis=0)  #summing cleaned, normalized data along the frequency axis\n",
    "                                        #shape = (512)\n",
    "    base = np.mean(f_summed)            #determining baseline as mean of the weights of the phases along the newly\\\n",
    "                                        #created frequency-summed-over array\n",
    "    sigma = np.std(f_summed)            #determining standard deviation of the weights of the phases along the newly\\\n",
    "                                        #created frequency-summed-over array\n",
    "    data_new_baseline = f_summed - base #determining data without baseline by subtracting baseline from newly created\\\n",
    "                                        #frequency-summed-over array\n",
    "    return data_new_baseline, sigma, base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pulse(data_new_baseline,sigma):\n",
    "    lower = int(len(data_new_baseline))     #initializing lower bound as maximum possible value\n",
    "    upper = 0                               #initializing upper bound as minimum possible value\n",
    "    for i in range(len(data_new_baseline)): #looping over all phases in baseline-corrected phase data\n",
    "        if (data_new_baseline[i] > sigma):  #conditional to check the positions in the array of the phase values which\n",
    "                                            #have a weight greater than a standard deviation\n",
    "            if lower>i:                     #determining lowest and higest values of the phase weights higher than one\n",
    "                                            #standard deviation to determine start and stop of phase\n",
    "                lower = i\n",
    "            elif upper<i:\n",
    "                upper = i\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(sorted(glob.glob('test_outputs/*.npy')))/2 #determining the number of files in the folder\n",
    "n = int(n) #converting number of files into an integer so it can be itterated over\n",
    "\n",
    "bounds = np.zeros((int(n*3),3)) #n number of files * 3 time bins per file length\n",
    "\n",
    "All_Folded_Data = np.zeros((n,3,32768,512,4)) #defining arrays to store all loaded data\n",
    "All_Count_Data = np.zeros((n,3,32768,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 3min 13s, total: 5min 1s\n",
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#master = np.zeros((len(data_fold[0,:,0,0]),n*3))\n",
    "k = 0\n",
    "for j in range(0,n,1):\n",
    "    folded = np.load(start+fold+str(pt[0,j])+\":\"+half_min_test(pt[1,j])+end+\".npy\")    #loading data from folded pulses\n",
    "    count = np.load(start+icount+str(pt[0,j])+\":\"+half_min_test(pt[1,j])+end+\".npy\") #loading data from icount file\n",
    "    All_Folded_Data[j] = folded #loading data into array containing all loaded data such that each file can be called upon later without need to load it into the notebook again\n",
    "    All_Count_Data[j] = count\n",
    "    normalized = normalize(folded,count) #normalizing data\n",
    "    summed = normalized[:,:,:,0]+normalized[:,:,:,3] #adding XX and YY polarization axis\n",
    "    for i in range(len(summed[:,0,0])): #iterating over time bins\n",
    "        \n",
    "        mean_data = meandiv_2(summed,i) #dividing my mean\n",
    "        no_baseline_data,stdev,base = remove_baseline(mean_data) #removing baseline data and determining baseline and standard deviation\n",
    "        lb,ub = find_pulse(no_baseline_data,stdev) #finding lower and upper bound for each pulse\n",
    "        \n",
    "        bounds[k] = (lb,ub,base) #storing the upper and lower bound values in an array contaning bounds for pulse for each time axis\n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n",
      "434\n"
     ]
    }
   ],
   "source": [
    "lower_bound = int(np.floor(np.mean(bounds[:,0]))) #determining average of lower and upper bounds to determine constant bounds\n",
    "upper_bound = int(np.ceil(np.mean(bounds[:,1])))\n",
    "print(upper_bound)\n",
    "print(lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulse_profile_2(data): #defining function to calculate weighted average of data clean data\n",
    "    upper = upper_bound\n",
    "    lower = lower_bound\n",
    "    \n",
    "    phase_only = np.mean(data,axis=0,keepdims=True) #averaging data along time axis, keeping dimensions\n",
    "    phase_only = np.sum(phase_only[0,:,:],axis=0) #averaging data along the frequency axis, result is a 1D array with weighted phase values\n",
    "    \n",
    "    profile = np.zeros_like(phase_only) #creating an array of 0's length equal to the number of phase bins\n",
    "    profile[lower:upper] = phase_only[lower:upper] #assinging pulse reigon of phase to on pulse profile array\n",
    "    \n",
    "    off_gate = np.zeros_like(phase_only) #creating an array of 0's length equal to the number of phase bins\n",
    "    off_gate[100:200] = 1 #assigning 1 to off pulse profile array over relativelly large phase interval not containing pulse\n",
    "    \n",
    "    weighted_avg_on = np.sum(data*profile,axis=2)/np.sum(profile) #calculating weighted average of on pulse data\n",
    "    \n",
    "    weighted_avg_off = np.sum(data*off_gate,axis=2)/np.sum(off_gate) #calculating weighted average of off pulse data\n",
    "    \n",
    "    cleaned_data = weighted_avg_on/weighted_avg_off - 1 #cleaning up data\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_bands_2(data):\n",
    "    for i in range(len(data[0,:])):\n",
    "        if (i >= 10500 and i <= 11700) or (i >= 13500 and i <= 14000) or (i >= 15000 and i <= 15500) or (i >= 26500 and i <= 29250): #conditional for noisy frequency bands\n",
    "            data[:,i] = 0           #weighing down the RFI frequencies\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "k=0\n",
    "h=0\n",
    "for j in range(0,n,1):\n",
    "    folded_data = All_Folded_Data[j] #getting raw folded data from master array\n",
    "    count_data = All_Count_Data[j] #getting raw count data from master array\n",
    "    normalized = normalize(folded_data,count_data) #normalizing raw data\n",
    "    summed_data = (normalized[:,:,:,0] + normalized[:,:,:,3]) #summing XX and YY polarization axis\n",
    "    \n",
    "    clean = pulse_profile_2(summed_data) #calculating weighted average of data and cleaning data\n",
    "\n",
    "    masked_pulse_data = mask_bands_2(clean) #masking noisy frequency channels\n",
    "\n",
    "    if (j == 0):\n",
    "        master_stack = masked_pulse_data #assigning data to master array for concatenation along time axis\n",
    "    else:\n",
    "        master_stack = np.concatenate((master_stack,masked_pulse_data)) #concatenating data to master array along time axis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(master_stack.shape) #result is a 1D array of time,frequency with shape (number of time bins per file * number of data files, number of frequency bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(master_stack.T,aspect='auto') #transposing concatenated data to ensure that x and y axis are correctly orientated on the plot\n",
    "plt.xlabel('Time', size=20)\n",
    "plt.ylabel('Frequency', size=20)\n",
    "plt.colorbar()\n",
    "plt.savefig('../Dynamic/Dynamic_Spectra_test_18.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
